# Sentry-Compatible Monitoring Architecture Plan

## Overview

Build a high-performance, Sentry-compatible error monitoring system using:

- **ClickHouse**: Time-series event storage and analytics
- **PostgreSQL**: Transactional data, error groups, and metadata
- **AdonisJS Jobs**: Async event processing pipeline
- **AI SDK**: Intelligent error grouping and analysis

## Database Architecture

### PostgreSQL (Transactional Data)

```
projects
├── id, name, slug, settings
├── rate_limits, sampling_config
└── ai_config (for intelligent grouping)

error_groups
├── id, project_id, fingerprint
├── title, status, first_seen, last_seen
├── metadata, tags, assignee
└── ai_summary (generated by Vercel AI)

error_occurrences
├── id, group_id, event_id
├── created_at
└── metadata

project_stats
├── project_id, date
├── error_count, unique_errors
└── performance_metrics
```

### ClickHouse (Time-Series Data)

```
error_events (existing)
├── Raw event data with 1-year TTL
├── Optimized for write-heavy workloads
└── Partitioned by month

error_metrics_hourly (new)
├── Aggregated hourly metrics
├── Pre-calculated for dashboards
└── 90-day retention

performance_events (future)
├── Transaction traces
├── Performance metrics
└── 30-day retention
```

## Event Processing Pipeline

### 1. Ingestion Layer

```typescript
// API receives event → Quick validation → Store in ClickHouse → Queue processing job
POST /api/:projectId/store
  ↓
Validate & Enrich
  ↓
ClickHouse (raw event)
  ↓
Queue ProcessEventJob
```

### 2. Processing Jobs

#### ProcessEventJob (Primary)

```typescript
export default class ProcessEventJob {
  static get key() {
    return 'process-event'
  }

  async handle(data: { eventId: string; projectId: string }) {
    // 1. Fetch raw event from ClickHouse
    // 2. Calculate fingerprint
    // 3. Find or create error group
    // 4. Update statistics
    // 5. Trigger AI analysis if needed
    // 6. Queue notification jobs
  }
}
```

#### AggregateMetricsJob (Scheduled)

```typescript
export default class AggregateMetricsJob {
  static get key() {
    return 'aggregate-metrics'
  }
  static get schedule() {
    return '0 * * * *'
  } // Hourly

  async handle() {
    // Aggregate ClickHouse data into hourly/daily metrics
    // Update PostgreSQL stats
    // Clean up old data
  }
}
```

#### AIAnalysisJob (Conditional)

```typescript
export default class AIAnalysisJob {
  static get key() {
    return 'ai-analysis'
  }

  async handle(data: { groupId: string }) {
    // Use Vercel AI SDK to:
    // - Generate error summaries
    // - Suggest fixes
    // - Find similar errors
    // - Classify severity
  }
}
```

## Fingerprinting Algorithm

### Hierarchical Approach

```typescript
function calculateFingerprint(event: ErrorEvent): string[] {
  // 1. Custom fingerprint (if provided)
  if (event.fingerprint?.length) {
    return event.fingerprint
  }

  // 2. Stack-based fingerprint
  if (event.exception?.values?.[0]?.stacktrace) {
    return generateStackFingerprint(event.exception.values[0].stacktrace)
  }

  // 3. Message-based fingerprint
  return [event.exception_type || 'unknown', normalizeMessage(event.message)]
}

function normalizeMessage(message: string): string {
  return message
    .replace(/\b\d+\b/g, 'N') // Numbers → N
    .replace(/\b0x[0-9a-f]+\b/gi, '0x') // Hex → 0x
    .replace(/\b[a-f0-9-]{36}\b/gi, 'UUID') // UUIDs → UUID
    .replace(/\/.+?\/([^\/]+)$/g, '/…/$1') // Paths → simplified
}
```

## Enhanced Seeding with Faker & AI

### 1. Realistic Error Patterns

```typescript
import { faker } from '@faker-js/faker'
import { generateText } from 'ai'

export class EnhancedErrorSeeder {
  // Generate thousands of realistic errors
  async generateErrors(count: number) {
    const errorPatterns = [
      this.generateJavaScriptErrors,
      this.generateAPIErrors,
      this.generateDatabaseErrors,
      this.generateValidationErrors,
      this.generatePerformanceErrors,
    ]

    // Use AI to generate realistic error messages
    const aiGeneratedErrors = await this.generateAIErrors(100)

    // Mix different patterns
    for (let i = 0; i < count; i++) {
      const pattern = faker.helpers.arrayElement(errorPatterns)
      await pattern.call(this)
    }
  }

  async generateAIErrors(count: number) {
    const { text } = await generateText({
      model: openai('gpt-4-turbo'),
      prompt: `Generate ${count} realistic production error messages for a web application. 
               Include stack traces, varying severity levels, and different error types.
               Format as JSON array.`,
    })

    return JSON.parse(text)
  }
}
```

### 2. Temporal Distribution

```typescript
// Simulate realistic error patterns over time
function generateTemporalDistribution(baseCount: number) {
  const events = []
  const now = new Date()

  // Normal distribution with spikes
  for (let day = 0; day < 30; day++) {
    const date = subDays(now, day)

    // Base load
    const dayCount = faker.number.int({ min: baseCount * 0.8, max: baseCount * 1.2 })

    // Add spike events (deployments, outages)
    if (faker.number.float() < 0.1) {
      dayCount *= faker.number.int({ min: 5, max: 20 })
    }

    // Distribute throughout the day
    for (let i = 0; i < dayCount; i++) {
      events.push({
        timestamp: faker.date.between({ from: startOfDay(date), to: endOfDay(date) }),
      })
    }
  }

  return events
}
```

## Sampling & Rate Limiting

### Dynamic Sampling

```typescript
export class DynamicSampler {
  async getSampleRate(projectId: string): Promise<number> {
    // Get current event rate from Redis
    const currentRate = await redis.get(`project:${projectId}:rate`)

    // Calculate dynamic sample rate
    if (currentRate > 10000) return 0.01 // 1% for high volume
    if (currentRate > 1000) return 0.1 // 10% for medium volume
    return 1.0 // 100% for low volume
  }

  shouldSample(sampleRate: number): boolean {
    return Math.random() < sampleRate
  }
}
```

## Performance Optimizations

### 1. Batch Processing

```typescript
// Process events in batches for efficiency
export class BatchProcessor {
  private queue: ErrorEvent[] = []
  private timer: NodeJS.Timeout

  async add(event: ErrorEvent) {
    this.queue.push(event)

    if (this.queue.length >= 100) {
      await this.flush()
    } else if (!this.timer) {
      this.timer = setTimeout(() => this.flush(), 1000)
    }
  }

  async flush() {
    const batch = this.queue.splice(0, 100)
    await ClickHouseService.batchInsert(batch)
  }
}
```

### 2. Caching Layer

```typescript
// Cache frequently accessed data
export class ErrorGroupCache {
  async getGroup(fingerprint: string): Promise<ErrorGroup> {
    const cached = await redis.get(`group:${fingerprint}`)
    if (cached) return JSON.parse(cached)

    const group = await ErrorGroup.findBy('fingerprint', fingerprint)
    await redis.setex(`group:${fingerprint}`, 3600, JSON.stringify(group))

    return group
  }
}
```

## Implementation Timeline

### Phase 1: Foundation (Week 1)

- [ ] Enhanced seeding with Faker
- [ ] Basic job processing pipeline
- [ ] Fingerprinting algorithm
- [ ] PostgreSQL schema for groups

### Phase 2: Processing (Week 2)

- [ ] ProcessEventJob implementation
- [ ] Dynamic sampling
- [ ] Rate limiting
- [ ] Batch processing

### Phase 3: Analytics (Week 3)

- [ ] Aggregation jobs
- [ ] ClickHouse materialized views
- [ ] Dashboard queries
- [ ] Performance monitoring

### Phase 4: AI Integration (Week 4)

- [ ] AI-powered error analysis
- [ ] Intelligent grouping
- [ ] Automated suggestions
- [ ] Anomaly detection

## Monitoring & Observability

### Key Metrics

- Event ingestion rate
- Processing lag
- Error group accuracy
- Storage efficiency
- Query performance

### Alerts

- Processing queue depth > 1000
- Ingestion failures > 1%
- Storage usage > 80%
- Query time > 1s

This architecture provides a scalable foundation that can handle millions of events while maintaining Sentry compatibility and adding intelligent features through AI integration.
