name: maya-adonisjs

services:
  # Database with PgAI integration
  pgsql:
    image: 'timescale/timescaledb-ha:pg17'
    container_name: 'maya_pgsql'
    ports:
      - '${DB_PORT:-5432}:5432'
    environment:
      POSTGRES_DB: '${DB_DATABASE:-default}'
      POSTGRES_USER: '${DB_USER:-postgres}'
      POSTGRES_PASSWORD: '${DB_PASSWORD:-secret}'
    volumes:
      - 'pgsql_data:/home/postgres/pgdata/data'
    networks:
      - maya_network
    command: ["-c", "ai.ollama_host=http://ollama:11434"]
    # Make Ollama dependency optional
    # depends_on:
    #   ollama:
    #     condition: service_started
    healthcheck:
      test: ['CMD', 'pg_isready', '-q', '-d', '${DB_DATABASE:-default}', '-U', '${DB_USER:-postgres}']
      retries: 3
      timeout: 5s
      interval: 10s

  # Redis for caching, session storage, and pub/sub
  redis:
    image: 'redis:7-alpine'
    container_name: 'maya_redis'
    ports:
      - '${REDIS_PORT:-6379}:6379'
    volumes:
      - 'redis_data:/data'
    networks:
      - maya_network
    healthcheck:
      test: ['CMD', 'redis-cli', 'ping']
      retries: 3
      timeout: 5s
      interval: 10s

  # ClickHouse for analytics
  clickhouse:
    image: 'clickhouse/clickhouse-server:23.8-alpine'
    container_name: 'maya_clickhouse'
    ports:
      - '${CLICKHOUSE_PORT:-8123}:8123' # HTTP port
      - '${CLICKHOUSE_NATIVE_PORT:-9000}:9000' # Native port
    volumes:
      - 'clickhouse_data:/var/lib/clickhouse'
    networks:
      - maya_network
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    healthcheck:
      test: ['CMD', 'wget', '--no-verbose', '--spider', '--tries=1', 'http://localhost:8123/ping']
      interval: 10s
      timeout: 5s
      retries: 3

  # Ollama for AI capabilities with Gemma 3 model
  ollama:
    image: 'ollama/ollama:latest'
    container_name: 'maya_ollama'
    volumes:
      - 'ollama_data:/root/.ollama'
    ports:
      - '${OLLAMA_PORT:-11434}:11434'
    networks:
      - maya_network
    command: ["serve"]
    # Disable health check for development
    # healthcheck:
    #   test: ["CMD", "curl", "-s", "-f", "http://localhost:11434/api/version" , "||" , "exit 0"]
    #   interval: 10s
    #   timeout: 5s
    #   retries: 5
    #   start_period: 20s

  # PgAI vectorizer worker for background processing
  pgai_vectorizer:
    image: 'timescale/pgai-vectorizer-worker:latest'
    container_name: 'maya_pgai_vectorizer'
    environment:
      PGAI_VECTORIZER_WORKER_DB_URL: postgres://${DB_USER:-postgres}:${DB_PASSWORD:-secret}@pgsql:5432/${DB_DATABASE:-default}
      OLLAMA_HOST: http://ollama:11434
    command: ["--poll-interval", "5s", "--log-level", "DEBUG"]
    networks:
      - maya_network
    depends_on:
      pgsql:
        condition: service_healthy
      # Make Ollama dependency optional
      # ollama:
      #   condition: service_started

  # Logto for authentication
  logto:
    image: 'svhd/logto:latest'
    container_name: 'maya_logto'
    depends_on:
      logto_postgres:
        condition: service_healthy
    entrypoint: ["sh", "-c", "npm run cli db seed -- --swe && npm start"]
    ports:
      - '${LOGTO_PORT:-3001}:3001'
      - '${LOGTO_ADMIN_PORT:-3002}:3002'
    environment:
      - TRUST_PROXY_HEADER=1
      - DB_URL=postgres://postgres:p0stgr3s@logto_postgres:5432/logto
      - ENDPOINT=${LOGTO_ENDPOINT:-http://localhost:3001}
      - ADMIN_ENDPOINT=${LOGTO_ADMIN_ENDPOINT:-http://localhost:3002}
    networks:
      - maya_network

  # Dedicated Postgres for Logto
  logto_postgres:
    image: 'postgres:17-alpine'
    container_name: 'maya_logto_postgres'
    user: postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: p0stgr3s
      POSTGRES_DB: logto
    volumes:
      - 'logto_postgres_data:/var/lib/postgresql/data'
    networks:
      - maya_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Initialize Gemma 3 model in Ollama
  init_gemma3:
    image: 'curlimages/curl:latest'
    container_name: 'maya_init_gemma3'
    networks:
      - maya_network
    # Make Ollama dependency optional
    # depends_on:
    #   ollama:
    #     condition: service_healthy
    command: ["-X", "POST", "http://ollama:11434/api/pull", "-d", '{"name":"gemma3:2b-instruct-q4_0"}']
    restart: "no"
    
  # MailHog for local email testing
  mailhog:
    image: 'mailhog/mailhog:latest'
    container_name: 'maya_mailhog'
    ports:
      - '${MAILHOG_SMTP_PORT:-1025}:1025' # SMTP server port
      - '${MAILHOG_UI_PORT:-8025}:8025' # Web UI port
    networks:
      - maya_network
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "8025"]
      interval: 10s
      timeout: 5s
      retries: 3
      
  # Web application (AdonisJS)
  web:
    build:
      context: .
      dockerfile: ./apps/web/Dockerfile
      target: development
    container_name: 'maya_web'
    restart: unless-stopped
    volumes:
      - ./apps/web:/app/apps/web
      - /app/apps/web/node_modules
    networks:
      - maya_network
    ports:
      - '${WEB_PORT:-3333}:3333'
    depends_on:
      pgsql:
        condition: service_healthy
      redis:
        condition: service_healthy
      mailhog:
        condition: service_healthy
    environment:
      HOST: 0.0.0.0
      PORT: 3333
      NODE_ENV: ${NODE_ENV:-development}
      DB_HOST: pgsql
      REDIS_HOST: redis
      LOGTO_URL: http://logto:3001/oidc/auth
      LOGTO_AUTHORIZE_URL: http://logto:3001/oidc/auth
      LOGTO_ACCESS_TOKEN_URL: http://logto:3001/oidc/token
      LOGTO_USER_INFO_URL: http://logto:3001/oidc/me
      
  # Documentation app (Next.js)
  docs:
    build:
      context: .
      dockerfile: ./apps/docs/Dockerfile
      target: development
    container_name: 'maya_docs'
    restart: unless-stopped
    volumes:
      - ./apps/docs:/app/apps/docs
      - /app/apps/docs/node_modules
    networks:
      - maya_network
    ports:
      - '${DOCS_PORT:-3300}:3300'
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      
  # Nginx proxy for routing
  proxy:
    build:
      context: ./.github/docker/nginx
      dockerfile: Dockerfile
    container_name: 'maya_proxy'
    restart: unless-stopped
    ports:
      - '${NGINX_PORT:-80}:80'
    environment:
      - NGINX_HOST=${NGINX_HOST:-localhost}
      - NGINX_PORT=80
      - WEB_PORT=${WEB_PORT:-3333}
      - DOCS_PORT=${DOCS_PORT:-3300}
    networks:
      - maya_network
    depends_on:
      - web
      - docs

networks:
  maya_network:
    driver: bridge



volumes:
  pgsql_data:
  redis_data:
  clickhouse_data:
  logto_postgres_data:
  ollama_data:
