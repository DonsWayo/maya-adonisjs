# Prometheus Stack Helm Values
# Optimized for Maya AdonisJS monitoring

# Prometheus Operator
prometheusOperator:
  resources:
    limits:
      cpu: 200m
      memory: 256Mi
    requests:
      cpu: 100m
      memory: 128Mi

# Prometheus Configuration
prometheus:
  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: traefik
      cert-manager.io/cluster-issuer: letsencrypt-prod
    hosts:
      - prometheus.${domain}
    tls:
      - secretName: prometheus-tls
        hosts:
          - prometheus.${domain}
  
  prometheusSpec:
    # Resource limits
    resources:
      limits:
        cpu: 1000m
        memory: 2Gi
      requests:
        cpu: 500m
        memory: 1Gi
    
    # Storage configuration
    retention: ${retention}
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: longhorn
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: ${storage_size}
    
    # Service monitors to scrape
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    ruleSelectorNilUsesHelmValues: false
    
    # Additional scrape configs for external services
    additionalScrapeConfigs:
      # Scrape ClickHouse metrics
      - job_name: 'clickhouse'
        static_configs:
          - targets: ['clickhouse.maya-data:9363']
        metrics_path: '/metrics'
      
      # Scrape Redis metrics via redis-exporter
      - job_name: 'redis'
        static_configs:
          - targets: ['redis-exporter.maya-data:9121']
      
      # Scrape PostgreSQL metrics via postgres-exporter
      - job_name: 'postgresql'
        static_configs:
          - targets: ['postgres-exporter.maya-data:9187']
      
      # Scrape AdonisJS application metrics
      - job_name: 'maya-apps'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names: ['maya-apps']
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__

# Grafana Configuration
grafana:
  enabled: true
  
  # Admin credentials
  adminPassword: "${grafana_password}"
  
  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: traefik
      cert-manager.io/cluster-issuer: letsencrypt-prod
    hosts:
      - grafana.${domain}
    tls:
      - secretName: grafana-tls
        hosts:
          - grafana.${domain}
  
  # Resource limits
  resources:
    limits:
      cpu: 200m
      memory: 256Mi
    requests:
      cpu: 100m
      memory: 128Mi
  
  # Persistence
  persistence:
    enabled: true
    storageClassName: longhorn
    size: 10Gi
  
  # Pre-installed dashboards
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: 'maya-dashboards'
          orgId: 1
          folder: 'Maya'
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/maya
  
  dashboardsConfigMaps:
    maya: "maya-dashboards"
  
  # Data sources
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          url: http://kube-prometheus-stack-prometheus:9090
          access: proxy
          isDefault: true
        
        - name: Loki
          type: loki
          url: http://loki:3100
          access: proxy
        
        - name: Tempo
          type: tempo
          url: http://tempo:3100
          access: proxy

# AlertManager Configuration
alertmanager:
  enabled: true
  
  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: traefik
      cert-manager.io/cluster-issuer: letsencrypt-prod
    hosts:
      - alertmanager.${domain}
    tls:
      - secretName: alertmanager-tls
        hosts:
          - alertmanager.${domain}
  
  alertmanagerSpec:
    # Resource limits
    resources:
      limits:
        cpu: 100m
        memory: 128Mi
      requests:
        cpu: 50m
        memory: 64Mi
    
    # Storage
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: longhorn
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 1Gi
  
  # Alert routing configuration
  config:
    global:
      resolve_timeout: 5m
      slack_api_url: "${slack_webhook_url}"
    
    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      receiver: 'default'
      routes:
        - match:
            severity: critical
          receiver: slack-critical
        - match:
            severity: warning
          receiver: slack-warning
    
    receivers:
      - name: 'default'
      
      - name: 'slack-critical'
        slack_configs:
          - channel: '#alerts-critical'
            title: 'Critical Alert'
            text: '{{ range .Alerts }}{{ .Annotations.summary }}\n{{ end }}'
            send_resolved: true
      
      - name: 'slack-warning'
        slack_configs:
          - channel: '#alerts-warning'
            title: 'Warning Alert'
            text: '{{ range .Alerts }}{{ .Annotations.summary }}\n{{ end }}'
            send_resolved: true

# Node Exporter
nodeExporter:
  enabled: true

# Kube State Metrics
kubeStateMetrics:
  enabled: true

# Additional Prometheus rules for Maya applications
additionalPrometheusRulesMap:
  maya-rules:
    groups:
      - name: maya-apps
        interval: 30s
        rules:
          # AdonisJS application alerts
          - alert: MayaAppDown
            expr: up{job="maya-apps"} == 0
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "Maya application is down"
              description: "{{ $labels.pod }} in namespace {{ $labels.namespace }} is down"
          
          - alert: MayaHighErrorRate
            expr: rate(adonis_http_request_duration_seconds_count{status=~"5.."}[5m]) > 0.1
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High error rate in Maya application"
              description: "Error rate is {{ $value }} errors per second"
          
          - alert: MayaHighResponseTime
            expr: histogram_quantile(0.95, rate(adonis_http_request_duration_seconds_bucket[5m])) > 1
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High response time in Maya application"
              description: "95th percentile response time is {{ $value }} seconds"
          
          # Database alerts
          - alert: PostgreSQLDown
            expr: pg_up == 0
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "PostgreSQL is down"
              description: "PostgreSQL instance {{ $labels.instance }} is down"
          
          - alert: RedisDown
            expr: redis_up == 0
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "Redis is down"
              description: "Redis instance {{ $labels.instance }} is down"
          
          - alert: ClickHouseDown
            expr: up{job="clickhouse"} == 0
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "ClickHouse is down"
              description: "ClickHouse instance {{ $labels.instance }} is down"